fitTrainingCO = lm(CO_y1~CO_x1 + CO_x2, data = TrainingCO)
# These are the predictions of the model on the data that were used to fit the model.
predsTrainingTX = predict(fitTrainingTX)
predsTrainingCO = predict(fitTrainingCO)
# These are the predictions of the model on the data that were NOT used to fit the model.
# This is a better measure of how the model will perform in real life
predsTestTX = predict(fitTrainingTX, newdata = TestTX)
predsTestCO = predict(fitTrainingCO, newdata = TestCO)
# Calculation of the MSE for the training set
MSEholderTrainingTX[TXsample/50] = sum((predsTrainingTX - TrainingTX$TX_y1)^2)/(length(TrainingTX$TX_y1) - 2)
# Calculation of the MSE for the training set
MSEholderTrainingTX = sum((predsTrainingTX - TrainingTX$TX_y1)^2)/(length(TrainingTX$TX_y1) - 2)
# Calculation of the MSE for the Test set
MSEholderTestTX = sum((predsTestTX - TestTX$TX_y1)^2)/(length(TestTX$TX_y1) - 2)
TrainingCO = c()
TestCO = c()
TrainingTX = c()
TestTX = c()
COsample <- 146
TXsample <- 89
TX_x1 = rnorm(TXsample,2,1)
TX_x2 = rgamma(TXsample,1,2)
CO_x1 = rnorm(COsample,2,1)
CO_x2 = rgamma(COsample,1,2)
#parameter setting ... these are the actual parameters that you would not know in a real world setting
true_beta_0 = 1.1
true_beta_1 = -1.2
true_beta_2 = 4
# error ~ N(0,2)  therefore Var(error) = 4
TX_true_error = rnorm(TXsample,0,5)
CO_true_error = rnorm(COsample,0,5)
#Generate Repsonses
TX_y1 = true_beta_0 + true_beta_1*TX_x1 + true_beta_2*TX_x2 + TX_true_error
CO_y1 = true_beta_0 + true_beta_1*CO_x1 + true_beta_2*CO_x2 + CO_true_error
# Make a dataframe to fit the model
TX_df1 = data.frame(TX_x1 = TX_x1, TX_x2 = TX_x2, TX_y1 = TX_y1)
CO_df1 = data.frame(CO_x1 = CO_x1, CO_x2 = CO_x2, CO_y1 = CO_y1)
#Divide into training and test set ... this one is 60% training 40% test
train_perc = .6
TX_train_indices = sample(seq(1,TXsample,length = TXsample),train_perc*TXsample)
TrainingTX = TX_df1[TX_train_indices,]
TestTX = TX_df1[-TX_train_indices,]
CO_train_indices = sample(seq(1,COsample,length = COsample),train_perc*COsample)
TrainingCO = TX_df1[CO_train_indices,]
TestCO = CO_df1[-CO_train_indices,]
#Fit the correct model
fitTrainingTX = lm(TX_y1~TX_x1 + TX_x2, data = TrainingTX)
fitTrainingCO = lm(CO_y1~CO_x1 + CO_x2, data = TrainingCO)
# These are the predictions of the model on the data that were used to fit the model.
predsTrainingTX = predict(fitTrainingTX)
predsTrainingCO = predict(fitTrainingCO)
# These are the predictions of the model on the data that were NOT used to fit the model.
# This is a better measure of how the model will perform in real life
predsTestTX = predict(fitTrainingTX, newdata = TestTX)
predsTestCO = predict(fitTrainingCO, newdata = TestCO)
# Calculation of the MSE for the training set
TrainingTX = sum((predsTrainingTX - TrainingTX$TX_y1)^2)/(length(TrainingTX$TX_y1) - 2)
# Calculation of the MSE for the Test set
TestTX = sum((predsTestTX - TestTX$TX_y1)^2)/(length(TestTX$TX_y1) - 2)
# Calculation of the MSE for the training set
TrainingCO = sum((predsTrainingCO - TrainingCO$CO_y1)^2)/(length(TrainingCO$CO_y1) - 2)
# Calculation of the MSE for the Test set
TestCO = sum((predsTestCO - TestCO$CO_y1)^2)/(length(TestCO$CO_y1) - 2)
#Fit the wrong model
fitTrainingCO = lm(TX_y1~TX_x1, data = TrainingTX)
TX_Confidence <- data.frame(ABV=.1)
predict(TXfit, newdata = TX_Confidence, interval = 'confidence')
COTX_Confidence <- data.frame(ABV=.1)
predict(COTXfit, newdata = COTX_Confidence, interval = 'confidence')
CO_Confidence <- data.frame(ABV=.1)
predict(COfit, newdata = CO_Confidence, interval = 'confidence')
CO_Count <- as.integer(146)
TX_Count <- as.integer(89)
CO_ABV_Median <- tapply(beerCO$ABV, beerCO$State, median, na.rm = TRUE)
CO_IBU_Median <- tapply(beerCO$IBU, beerCO$IBU, median, na.rm = TRUE)
CO_ABV_Max <- max(beerCO$ABV, na.rm = TRUE)
CO_IBU_Max <- max(beerCO$IBU, na.rm = TRUE)
TX_ABV_Median <- tapply(beerTX$ABV, beerTX$State, median, na.rm = TRUE)
TX_IBU_Median <- tapply(beerTX$IBU, beerTX$State, median, na.rm = TRUE)
TX_ABV_Max <- max(beerTX$ABV, na.rm = TRUE)
TX_IBU_Max <- max(beerTX$IBU, na.rm = TRUE)
COTX_ABV_Median <- tapply(beerCOTX$ABV, beerCOTX$State, median, na.rm = TRUE)
COTX_IBU_Median <- tapply(beerCOTX$IBU, beerCOTX$State, median, na.rm = TRUE)
COTX_ABV_Max <- max(beerCOTX$ABV, na.rm = TRUE)
COTX_IBU_Max <- max(beerCOTX$IBU, na.rm = TRUE)
COfit = lm(beerCO$ABV ~ beerCO$IBU + beerCO$IBU,data = beerCO) # fit the model to get Beta_hat_0 and Beta_hat_1
COcoefs <- coef(COfit)
COSummary <- summary(COfit) # view the parameter estimate table
COfit_r2 <- c("0.4433")
COsigma <- sigma(COfit)
TXfit = lm(beerTX$ABV ~ beerTX$IBU + beerTX$IBU,data = beerTX) # fit the model to get Beta_hat_0 and Beta_hat_1
TXcoefs <- coef(TXfit)
TXSummary <- summary(TXfit) # view the parameter estimate table
TXfit_r2 <- c("0.596")
TXsigma <- sigma(TXfit)
COTXfit = lm(beerCOTX$ABV ~ beerCOTX$IBU + beerCOTX$IBU,data = beerCOTX) # fit the model to get Beta_hat_0 and Beta_hat_1
COTXcoefs <- coef(COTXfit)
COTXSummary <- summary(COTXfit) # view the parameter estimate table
COTXfit_r2 <- c("0.5061")
COTXsigma <- sigma(COTXfit)
p <- ggplot(beerCOTX, aes(x=IBU, y=ABV, colour=State, size=ABV)) + geom_point()
p
p + stat_smooth(method = lm, se = FALSE, fullrange = TRUE, level = 0.99) + scale_shape_manual(values = c(20,20)) + scale_size_area() + scale_color_brewer(palette = "Set1")
p + stat_smooth(method = lm, se = FALSE, fullrange = TRUE, level = 0.99) +scale_shape_manual(values = c(20,20)) + scale_size_area() + scale_color_brewer(palette = "Set1") + facet_wrap( ~ State)
#barplot(beerCOTX$IBU)
plot(beerTX$IBU,beerTX$ABV, pch = 20, col = "red", xlab = "International Bitterness Units", ylab ="Alcohol By Volume", main = "ABV v. IBU of Texas Beers", sub = "r^2 = 0.596")
abline(TXcoefs[1], TXcoefs[2])
TXsigma <- sigma(TXfit)
plot(beerCO$IBU,beerCO$ABV, pch = 20, col = "blue", xlab = "International Bitterness Units", ylab = "Alcohol By Volume", main = "ABV v. IBU of Colorado Beers", sub = "r^2 = 0.4433")
abline(COcoefs[1], COcoefs[2])
plot(beerCOTX$ABV,beerCOTX$IBU, pch = 20, col = "blue", xlab = "International Bitterness Units", ylab = "Alcohol By Volume", main = "ABV v. IBU of Texas and Colorado Beers", sub = "r^2 = 0.5061")
abline(COTXcoefs[1], COTXcoefs[2])
TX_Confidence <- data.frame(TX$ABV =.1)
TX_Confidence <- data.frame(ABV =.1)
predict(TXfit, newdata = TX_Confidence, interval = 'confidence')
COTX_Confidence <- data.frame(CABV=.1)
predict(COTXfit, newdata = COTX_Confidence, interval = 'confidence')
CO_Confidence <- data.frame(ABV=.1)
predict(COfit, newdata = CO_Confidence, interval = 'confidence')
TX_Confidence <- data.frame(ABV =.1)
predict(TXfit, newdata = TX_Confidence, interval = 'confidence')
COTX_Confidence <- data.frame(ABV=.1)
predict(COTXfit, newdata = COTX_Confidence, interval = 'confidence')
CO_Confidence <- data.frame(ABV=.1)
predict(COfit, newdata = CO_Confidence, interval = 'confidence')
par(mfrow = c(1,1))
plot(seq(50,500,50), TrainingTX, ylim = c(0,100),type = "l")
par(mfrow = c(1,1))
plot(seq(50,500,50), TrainingTX, ylim = c(0,1),type = "l")
par(mfrow = c(1,1))
plot(beerTX$IBU, TrainingTX, ylim = c(0,1),type = "l")
TrainingCO = c()
TestCO = c()
TrainingTX = c()
TestTX = c()
COsample <- 146
TXsample <- 89
TX_x1 = rnorm(TXsample,2,1)
TX_x2 = rgamma(TXsample,1,2)
CO_x1 = rnorm(COsample,2,1)
CO_x2 = rgamma(COsample,1,2)
#parameter setting ... these are the actual parameters that you would not know in a real world setting
true_beta_0 = 1.1
true_beta_1 = -1.2
true_beta_2 = 4
# error ~ N(0,2)  therefore Var(error) = 4
TX_true_error = rnorm(TXsample,0,5)
CO_true_error = rnorm(COsample,0,5)
#Generate Repsonses
TX_y1 = true_beta_0 + true_beta_1*TX_x1 + true_beta_2*TX_x2 + TX_true_error
CO_y1 = true_beta_0 + true_beta_1*CO_x1 + true_beta_2*CO_x2 + CO_true_error
# Make a dataframe to fit the model
TX_df1 = data.frame(TX_x1 = TX_x1, TX_x2 = TX_x2, TX_y1 = TX_y1)
CO_df1 = data.frame(CO_x1 = CO_x1, CO_x2 = CO_x2, CO_y1 = CO_y1)
#Divide into training and test set ... this one is 60% training 40% test
train_perc = .6
TX_train_indices = sample(seq(1,TXsample,length = TXsample),train_perc*TXsample)
TrainingTX = TX_df1[TX_train_indices,]
TestTX = TX_df1[-TX_train_indices,]
CO_train_indices = sample(seq(1,COsample,length = COsample),train_perc*COsample)
TrainingCO = TX_df1[CO_train_indices,]
TestCO = CO_df1[-CO_train_indices,]
#Fit the correct model Model 1:  ABV= β_0+β_1 IBU
fitTrainingTX = lm(TX_y1~TX_x1 + TX_x2, data = TrainingTX)
fitTrainingCO = lm(CO_y1~CO_x1 + CO_x2, data = TrainingCO)
# These are the predictions of the model on the data that were used to fit the model.
predsTrainingTX = predict(fitTrainingTX)
predsTrainingCO = predict(fitTrainingCO)
# These are the predictions of the model on the data that were NOT used to fit the model.
# This is a better measure of how the model will perform in real life
predsTestTX = predict(fitTrainingTX, newdata = TestTX)
predsTestCO = predict(fitTrainingCO, newdata = TestCO)
# Calculation of the MSE for the training set
TrainingTX = sum((predsTrainingTX - TrainingTX$TX_y1)^2)/(length(TrainingTX$TX_y1) - 2)
# Calculation of the MSE for the Test set
TestTX = sum((predsTestTX - TestTX$TX_y1)^2)/(length(TestTX$TX_y1) - 2)
# Calculation of the MSE for the training set
TrainingCO = sum((predsTrainingCO - TrainingCO$CO_y1)^2)/(length(TrainingCO$CO_y1) - 2)
# Calculation of the MSE for the Test set
TestCO = sum((predsTestCO - TestCO$CO_y1)^2)/(length(TestCO$CO_y1) - 2)
#Fit the wrong model
fitTrainingCO = lm(TX_y1~TX_x1, data = TrainingTX)
TrainingCO = c()
TestCO = c()
TrainingTX = c()
TestTX = c()
COsample <- 146
TXsample <- 89
TX_x1 = rnorm(TXsample,2,1)
TX_x2 = rgamma(TXsample,1,2)
CO_x1 = rnorm(COsample,2,1)
CO_x2 = rgamma(COsample,1,2)
#parameter setting ... these are the actual parameters that you would not know in a real world setting
true_beta_0 = 1.1
true_beta_1 = -1.2
true_beta_2 = 4
# error ~ N(0,2)  therefore Var(error) = 4
TX_true_error = rnorm(TXsample,0,5)
CO_true_error = rnorm(COsample,0,5)
#Generate Repsonses
TX_y1 = true_beta_0 + true_beta_1*TX_x1 + true_beta_2*TX_x2 + TX_true_error
CO_y1 = true_beta_0 + true_beta_1*CO_x1 + true_beta_2*CO_x2 + CO_true_error
# Make a dataframe to fit the model
TX_df1 = data.frame(TX_x1 = TX_x1, TX_x2 = TX_x2, TX_y1 = TX_y1)
CO_df1 = data.frame(CO_x1 = CO_x1, CO_x2 = CO_x2, CO_y1 = CO_y1)
#Divide into training and test set ... this one is 60% training 40% test
train_perc = .6
TX_train_indices = sample(seq(1,TXsample,length = TXsample),train_perc*TXsample)
TrainingTX = TX_df1[TX_train_indices,]
TestTX = TX_df1[-TX_train_indices,]
CO_train_indices = sample(seq(1,COsample,length = COsample),train_perc*COsample)
TrainingCO = TX_df1[CO_train_indices,]
TestCO = CO_df1[-CO_train_indices,]
#Fit the correct model Model 1:  ABV= β_0+β_1 IBU
fitTrainingTX = lm(TX_y1~TX_x1 + TX_x2, data = TrainingTX)
fitTrainingCO = lm(CO_y1~CO_x1 + CO_x2, data = TrainingCO)
# These are the predictions of the model on the data that were used to fit the model.
predsTrainingTX = predict(fitTrainingTX)
predsTrainingCO = predict(fitTrainingCO)
# These are the predictions of the model on the data that were NOT used to fit the model.
# This is a better measure of how the model will perform in real life
predsTestTX = predict(fitTrainingTX, newdata = TestTX)
predsTestCO = predict(fitTrainingCO, newdata = TestCO)
# Calculation of the MSE for the training set
TrainingTX = sum((predsTrainingTX - TrainingTX$TX_y1)^2)/(length(TrainingTX$TX_y1) - 2)
# Calculation of the MSE for the Test set
TestTX = sum((predsTestTX - TestTX$TX_y1)^2)/(length(TestTX$TX_y1) - 2)
# Calculation of the MSE for the training set
TrainingCO = sum((predsTrainingCO - TrainingCO$CO_y1)^2)/(length(TrainingCO$CO_y1) - 2)
# Calculation of the MSE for the Test set
TestCO = sum((predsTestCO - TestCO$CO_y1)^2)/(length(TestCO$CO_y1) - 2)
#Fit the wrong model
#fitTrainingCO = lm(TX_y1~TX_x1, data = TrainingTX)
# These are the predictions of the model on the data that were used to fit the model.
#predsTrainingCO = predict(fitTrainingCO)
# These are the predictions of the model on the data that were NOT used to fit the model.
# This is a better measure of how the model will perform in real life
#predsTestCO = predict(fitTrainingCO, newdata = TestTX)
#Fit the wrong model Model 2:ABV= β_0+β_1 IBU+β_2 〖IBU〗^2
fitTrainingTX = lm(CO_y1~CO_x1, data = TrainingCO)
# These are the predictions of the model on the data that were used to fit the model.
predsTrainingTX = predict(fitTrain1)
TrainingCO = c()
TestCO = c()
TrainingTX = c()
TestTX = c()
COsample <- 146
TXsample <- 89
TX_x1 = rnorm(TXsample,2,1)
TX_x2 = rgamma(TXsample,1,2)
CO_x1 = rnorm(COsample,2,1)
CO_x2 = rgamma(COsample,1,2)
#parameter setting ... these are the actual parameters that you would not know in a real world setting
true_beta_0 = 1.1
true_beta_1 = -1.2
true_beta_2 = 4
# error ~ N(0,2)  therefore Var(error) = 4
TX_true_error = rnorm(TXsample,0,5)
CO_true_error = rnorm(COsample,0,5)
#Generate Repsonses
TX_y1 = true_beta_0 + true_beta_1*TX_x1 + true_beta_2*TX_x2 + TX_true_error
CO_y1 = true_beta_0 + true_beta_1*CO_x1 + true_beta_2*CO_x2 + CO_true_error
# Make a dataframe to fit the model
TX_df1 = data.frame(TX_x1 = TX_x1, TX_x2 = TX_x2, TX_y1 = TX_y1)
CO_df1 = data.frame(CO_x1 = CO_x1, CO_x2 = CO_x2, CO_y1 = CO_y1)
#Divide into training and test set ... this one is 60% training 40% test
train_perc = .6
TX_train_indices = sample(seq(1,TXsample,length = TXsample),train_perc*TXsample)
TrainingTX = TX_df1[TX_train_indices,]
TestTX = TX_df1[-TX_train_indices,]
CO_train_indices = sample(seq(1,COsample,length = COsample),train_perc*COsample)
TrainingCO = TX_df1[CO_train_indices,]
TestCO = CO_df1[-CO_train_indices,]
#Fit the correct model Model 1:  ABV= β_0+β_1 IBU
fitTrainingTX = lm(TX_y1~TX_x1 + TX_x2, data = TrainingTX)
fitTrainingCO = lm(CO_y1~CO_x1 + CO_x2, data = TrainingCO)
# These are the predictions of the model on the data that were used to fit the model.
predsTrainingTX = predict(fitTrainingTX)
predsTrainingCO = predict(fitTrainingCO)
# These are the predictions of the model on the data that were NOT used to fit the model.
# This is a better measure of how the model will perform in real life
predsTestTX = predict(fitTrainingTX, newdata = TestTX)
predsTestCO = predict(fitTrainingCO, newdata = TestCO)
# Calculation of the MSE for the training set
TrainingTX = sum((predsTrainingTX - TrainingTX$TX_y1)^2)/(length(TrainingTX$TX_y1) - 2)
# Calculation of the MSE for the Test set
TestTX = sum((predsTestTX - TestTX$TX_y1)^2)/(length(TestTX$TX_y1) - 2)
# Calculation of the MSE for the training set
TrainingCO = sum((predsTrainingCO - TrainingCO$CO_y1)^2)/(length(TrainingCO$CO_y1) - 2)
# Calculation of the MSE for the Test set
TestCO = sum((predsTestCO - TestCO$CO_y1)^2)/(length(TestCO$CO_y1) - 2)
#Fit the wrong model
#fitTrainingCO = lm(TX_y1~TX_x1, data = TrainingTX)
# These are the predictions of the model on the data that were used to fit the model.
#predsTrainingCO = predict(fitTrainingCO)
# These are the predictions of the model on the data that were NOT used to fit the model.
# This is a better measure of how the model will perform in real life
#predsTestCO = predict(fitTrainingCO, newdata = TestTX)
#Fit the wrong model Model 2:ABV= β_0+β_1 IBU+β_2 〖IBU〗^2
fitTrainingTX = lm(CO_y1~CO_x1, data = TrainingCO)
# These are the predictions of the model on the data that were used to fit the model.
predsTrainingTX = predict(fitTrainingCO)
# These are the predictions of the model on the data that were NOT used to fit the model.
# This is a better measure of how the model will perform in real life
predsTestTX = predict(fitTrainingTX, newdata = TestCO)
TrainingCO = c()
TestCO = c()
TrainingTX = c()
TestTX = c()
COsample <- 146
TXsample <- 89
TX_x1 = rnorm(TXsample,2,1)
TX_x2 = rgamma(TXsample,1,2)
CO_x1 = rnorm(COsample,2,1)
CO_x2 = rgamma(COsample,1,2)
#parameter setting ... these are the actual parameters that you would not know in a real world setting
true_beta_0 = 1.1
true_beta_1 = -1.2
true_beta_2 = 4
# error ~ N(0,2)  therefore Var(error) = 4
TX_true_error = rnorm(TXsample,0,5)
CO_true_error = rnorm(COsample,0,5)
#Generate Repsonses
TX_y1 = true_beta_0 + true_beta_1*TX_x1 + true_beta_2*TX_x2 + TX_true_error
CO_y1 = true_beta_0 + true_beta_1*CO_x1 + true_beta_2*CO_x2 + CO_true_error
# Make a dataframe to fit the model
TX_df1 = data.frame(TX_x1 = TX_x1, TX_x2 = TX_x2, TX_y1 = TX_y1)
CO_df1 = data.frame(CO_x1 = CO_x1, CO_x2 = CO_x2, CO_y1 = CO_y1)
#Divide into training and test set ... this one is 60% training 40% test
train_perc = .6
TX_train_indices = sample(seq(1,TXsample,length = TXsample),train_perc*TXsample)
TrainingTX = TX_df1[TX_train_indices,]
TestTX = TX_df1[-TX_train_indices,]
CO_train_indices = sample(seq(1,COsample,length = COsample),train_perc*COsample)
TrainingCO = TX_df1[CO_train_indices,]
TestCO = CO_df1[-CO_train_indices,]
#Fit the correct model Model 1:  ABV= β_0+β_1 IBU
fitTrainingTX = lm(TX_y1~TX_x1 + TX_x2, data = TrainingTX)
fitTrainingCO = lm(CO_y1~CO_x1 + CO_x2, data = TrainingCO)
# These are the predictions of the model on the data that were used to fit the model.
predsTrainingTX = predict(fitTrainingTX)
predsTrainingCO = predict(fitTrainingCO)
# These are the predictions of the model on the data that were NOT used to fit the model.
# This is a better measure of how the model will perform in real life
predsTestTX = predict(fitTrainingTX, newdata = TestTX)
predsTestCO = predict(fitTrainingCO, newdata = TestCO)
# Calculation of the MSE for the training set
TrainingTX = sum((predsTrainingTX - TrainingTX$TX_y1)^2)/(length(TrainingTX$TX_y1) - 2)
# Calculation of the MSE for the Test set
TestTX = sum((predsTestTX - TestTX$TX_y1)^2)/(length(TestTX$TX_y1) - 2)
# Calculation of the MSE for the training set
TrainingCO = sum((predsTrainingCO - TrainingCO$CO_y1)^2)/(length(TrainingCO$CO_y1) - 2)
# Calculation of the MSE for the Test set
TestCO = sum((predsTestCO - TestCO$CO_y1)^2)/(length(TestCO$CO_y1) - 2)
#Fit the wrong model
#fitTrainingCO = lm(TX_y1~TX_x1, data = TrainingTX)
# These are the predictions of the model on the data that were used to fit the model.
#predsTrainingCO = predict(fitTrainingCO)
# These are the predictions of the model on the data that were NOT used to fit the model.
# This is a better measure of how the model will perform in real life
#predsTestCO = predict(fitTrainingCO, newdata = TestTX)
#Fit the wrong model Model 2:ABV= β_0+β_1 IBU+β_2 〖IBU〗^2
fitTrainingTX = lm(CO_y1~CO_x1, data = TrainingCO)
# These are the predictions of the model on the data that were used to fit the model.
predsTrainingTX = predict(fitTrainingCO)
# These are the predictions of the model on the data that were NOT used to fit the model.
# This is a better measure of how the model will perform in real life
predsTestTX = predict(fitTrainingTX, newdata = TestCO)
TrainingCO = c()
TestCO = c()
TrainingTX = c()
TestTX = c()
COsample <- 146
TXsample <- 89
TX_x1 = rnorm(TXsample,2,1)
TX_x2 = rgamma(TXsample,1,2)
CO_x1 = rnorm(COsample,2,1)
CO_x2 = rgamma(COsample,1,2)
#parameter setting ... these are the actual parameters that you would not know in a real world setting
true_beta_0 = 1.1
true_beta_1 = -1.2
true_beta_2 = 4
# error ~ N(0,2)  therefore Var(error) = 4
TX_true_error = rnorm(TXsample,0,5)
CO_true_error = rnorm(COsample,0,5)
#Generate Repsonses
TX_y1 = true_beta_0 + true_beta_1*TX_x1 + true_beta_2*TX_x2 + TX_true_error
CO_y1 = true_beta_0 + true_beta_1*CO_x1 + true_beta_2*CO_x2 + CO_true_error
# Make a dataframe to fit the model
TX_df1 = data.frame(TX_x1 = TX_x1, TX_x2 = TX_x2, TX_y1 = TX_y1)
CO_df1 = data.frame(CO_x1 = CO_x1, CO_x2 = CO_x2, CO_y1 = CO_y1)
#Divide into training and test set ... this one is 60% training 40% test
train_perc = .6
TX_train_indices = sample(seq(1,TXsample,length = TXsample),train_perc*TXsample)
TrainingTX = TX_df1[TX_train_indices,]
TestTX = TX_df1[-TX_train_indices,]
CO_train_indices = sample(seq(1,COsample,length = COsample),train_perc*COsample)
TrainingCO = TX_df1[CO_train_indices,]
TestCO = CO_df1[-CO_train_indices,]
#Fit the correct model Model 1:  ABV= β_0+β_1 IBU
fitTrainingTX = lm(TX_y1~TX_x1 + TX_x2, data = TrainingTX)
fitTrainingCO = lm(CO_y1~CO_x1 + CO_x2, data = TrainingCO)
# These are the predictions of the model on the data that were used to fit the model.
predsTrainingTX = predict(fitTrainingTX)
predsTrainingCO = predict(fitTrainingCO)
# These are the predictions of the model on the data that were NOT used to fit the model.
# This is a better measure of how the model will perform in real life
predsTestTX = predict(fitTrainingTX, newdata = TestTX)
predsTestCO = predict(fitTrainingCO, newdata = TestCO)
# Calculation of the MSE for the training set
TrainingTX = sum((predsTrainingTX - TrainingTX$TX_y1)^2)/(length(TrainingTX$TX_y1) - 2)
# Calculation of the MSE for the Test set
TestTX = sum((predsTestTX - TestTX$TX_y1)^2)/(length(TestTX$TX_y1) - 2)
# Calculation of the MSE for the training set
TrainingCO = sum((predsTrainingCO - TrainingCO$CO_y1)^2)/(length(TrainingCO$CO_y1) - 2)
# Calculation of the MSE for the Test set
TestCO = sum((predsTestCO - TestCO$CO_y1)^2)/(length(TestCO$CO_y1) - 2)
#Fit the wrong model
#fitTrainingCO = lm(TX_y1~TX_x1, data = TrainingTX)
# These are the predictions of the model on the data that were used to fit the model.
#predsTrainingCO = predict(fitTrainingCO)
# These are the predictions of the model on the data that were NOT used to fit the model.
# This is a better measure of how the model will perform in real life
#predsTestCO = predict(fitTrainingCO, newdata = TestTX)
#Fit the wrong model Model 2:ABV= β_0+β_1 IBU+β_2 〖IBU〗^2
fitTrainingTX = lm(CO_y1~CO_x1, data = TrainingCO)
# These are the predictions of the model on the data that were used to fit the model.
predsTrainingTX = predict(fitTrainingCO)
# These are the predictions of the model on the data that were NOT used to fit the model.
# This is a better measure of how the model will perform in real life
#predsTestTX = predict(fitTrainingTX, newdata = TestCO)
# Calculation of the MSE for the training set
TrainingCO = sum((predsTrainingCO - TrainingTX$TX_y1)^2)/(length(TrainingTX$TX_y1) - 2)
TrainingCO = c()
TestCO = c()
TrainingTX = c()
TestTX = c()
COsample <- 146
TXsample <- 89
TX_x1 = rnorm(TXsample,2,1)
TX_x2 = rgamma(TXsample,1,2)
CO_x1 = rnorm(COsample,2,1)
CO_x2 = rgamma(COsample,1,2)
#parameter setting ... these are the actual parameters that you would not know in a real world setting
true_beta_0 = 1.1
true_beta_1 = -1.2
true_beta_2 = 4
# error ~ N(0,2)  therefore Var(error) = 4
TX_true_error = rnorm(TXsample,0,5)
CO_true_error = rnorm(COsample,0,5)
#Generate Repsonses
TX_y1 = true_beta_0 + true_beta_1*TX_x1 + true_beta_2*TX_x2 + TX_true_error
CO_y1 = true_beta_0 + true_beta_1*CO_x1 + true_beta_2*CO_x2 + CO_true_error
# Make a dataframe to fit the model
TX_df1 = data.frame(TX_x1 = TX_x1, TX_x2 = TX_x2, TX_y1 = TX_y1)
CO_df1 = data.frame(CO_x1 = CO_x1, CO_x2 = CO_x2, CO_y1 = CO_y1)
#Divide into training and test set ... this one is 60% training 40% test
train_perc = .6
TX_train_indices = sample(seq(1,TXsample,length = TXsample),train_perc*TXsample)
TrainingTX = TX_df1[TX_train_indices,]
TestTX = TX_df1[-TX_train_indices,]
CO_train_indices = sample(seq(1,COsample,length = COsample),train_perc*COsample)
TrainingCO = TX_df1[CO_train_indices,]
TestCO = CO_df1[-CO_train_indices,]
#Fit the correct model Model 1:  ABV= β_0+β_1 IBU
fitTrainingTX = lm(TX_y1~TX_x1 + TX_x2, data = TrainingTX)
fitTrainingCO = lm(CO_y1~CO_x1 + CO_x2, data = TrainingCO)
# These are the predictions of the model on the data that were used to fit the model.
predsTrainingTX = predict(fitTrainingTX)
predsTrainingCO = predict(fitTrainingCO)
# These are the predictions of the model on the data that were NOT used to fit the model.
# This is a better measure of how the model will perform in real life
predsTestTX = predict(fitTrainingTX, newdata = TestTX)
predsTestCO = predict(fitTrainingCO, newdata = TestCO)
# Calculation of the MSE for the training set
TrainingTX = sum((predsTrainingTX - TrainingTX$TX_y1)^2)/(length(TrainingTX$TX_y1) - 2)
# Calculation of the MSE for the Test set
TestTX = sum((predsTestTX - TestTX$TX_y1)^2)/(length(TestTX$TX_y1) - 2)
# Calculation of the MSE for the training set
TrainingCO = sum((predsTrainingCO - TrainingCO$CO_y1)^2)/(length(TrainingCO$CO_y1) - 2)
# Calculation of the MSE for the Test set
TestCO = sum((predsTestCO - TestCO$CO_y1)^2)/(length(TestCO$CO_y1) - 2)
#Fit the wrong model
#fitTrainingCO = lm(TX_y1~TX_x1, data = TrainingTX)
# These are the predictions of the model on the data that were used to fit the model.
#predsTrainingCO = predict(fitTrainingCO)
# These are the predictions of the model on the data that were NOT used to fit the model.
# This is a better measure of how the model will perform in real life
#predsTestCO = predict(fitTrainingCO, newdata = TestTX)
#Fit the wrong model Model 2:ABV= β_0+β_1 IBU+β_2 〖IBU〗^2
fitTrainingTX = lm(CO_y1~CO_x1, data = TrainingCO)
# These are the predictions of the model on the data that were used to fit the model.
predsTrainingTX = predict(fitTrainingCO)
# These are the predictions of the model on the data that were NOT used to fit the model.
# This is a better measure of how the model will perform in real life
#predsTestTX = predict(fitTrainingTX, newdata = TestCO)
# Calculation of the MSE for the training set
TrainingCO = sum((predsTrainingCO - TX_y1)^2)/(length(TX_y1) - 2)
# Calculation of the MSE for the Test set
TestCO = sum((predsTestCO - TX_y1)^2)/(length(TX_y1) - 2)
# Calculation of the MSE for the training set
TrainingTX = sum((predsTrainingCO - CO_y1)^2)/(length(CO_y1) - 2)
# Calculation of the MSE for the Test set
TestTX = sum((predsTestTX - CO_y1)^2)/(length(CO_y1) - 2)
TrainingTX
TestTX
TrainingCO
TestTX
summary(fitTrainingTX)
summary(fitTrainingCO)
summary(fitTrainingTX)
summary(fitTrainingCO)
